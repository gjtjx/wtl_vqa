function net = word_and_vision_regions_inner_network_init_wkshp(num_answers, varargin)
    opts.scale = 1;
    opts.initBias = 0.1;
    opts.weightDecay = 1;
    opts.cudnnWorkspaceLimit=4*1024*1024*1024;
    opts = vl_argparse(opts, varargin);
    num_ans = num_answers;
    net.normalization.imageSize = [1, num_ans, 1500];
    net.normalization.keepAspect = true ;

    net.layers = {};
    
    % Block 1
    net = addBlock(net, opts, 1, 1, 1, 1500, 2048 , 1, 0);
    
    % Block 2
    net = addBlock(net, opts, 2, 1, 1, 2048, 1500, 1, 0);
    
    
    % Block 3  
    net = addBlock(net, opts, 3, 1, 1, 1500, 1024, 1, 0);    
    J = 2048;
    G = 900;
    % fix scaling of weights
    % initialize biases to 0
    
    net.layers{end+1} = struct( ...
        'name', 'loc_attn', ...
        'type', 'custom', ...
        'forward', @(layer, res_i, res_ip1) regionsProjectInnerLayer( ...
            layer, res_i, res_ip1, true,opts), ...
        'backward', @(layer, res_i, res_ip1) regionsProjectInnerLayer( ...
            layer, res_i, res_ip1, false,opts), ...
        'weights', {{0.001*randn(1, 1, 1024, G, 'single'), zeros(1, G,'single'), ...
                     0.001*randn(1, 1, 5096, G, 'single'), zeros(1, G,'single'), ...
                     0.001*randn(1, 1, 1024, J, 'single'), zeros(1, J,'single'), ...
                     0.001*randn(1, 1, 5096, J, 'single'), zeros(1,J,'single'), ...
                    }}, ...
        'learningRate', [[1 2 1 2]*0.5 [1 2 1 2] ], ...
        'weightDecay', [1 0 1 0 1 0 1 0 ]);

        % net.layers{end+1} = struct( ...
    %     'type', 'custom', ...
    %     'forward', @(layer, res_i, res_ip1) regionsProjectInnerLayer( ...
    %         layer, res_i, res_ip1, true), ...
    %     'backward', @(layer, res_i, res_ip1) regionsProjectInnerLayer( ...
    %         layer, res_i, res_ip1, false), ...
    %     'weights', {{0.001/opts.scale*randn(1, 1, 1024, G, 'single'), zeros(1, G,'single'), ...
    %                  0.001/opts.scale*randn(1, 1, 5096, G, 'single'), zeros(1,G,'single'), ...
    %                  0.01/opts.scale*randn(1, 1, 1024, H, 'single'), zeros(1, H,'single'), ...
    %                  0.01/opts.scale*randn(1, 1, 5096, H, 'single'), zeros(1,H,'single'), ...
    %                  0.01/opts.scale*randn(1, 1, H, J, 'single'), zeros(1,J,'single'), ...
    %                 }}, ...
    %     'learningRate', [1 2 1 2 1 2 1 2 1 2], ...
    %     'weightDecay', [1 0 1 0 1 0 1 0 1 0]);

        % Block 4
        net.layers{end+1} = struct('type', 'bnorm', 'name', sprintf('bn%d',32), ...
                                   'weights', {{ones(J, 1, 'single'), zeros(J, 1, 'single'),zeros(J,2, 'single')}}, ...
                                   'learningRate', [2 1 0.05], ...
                                   'weightDecay', [0 0]) ;
        
        net.layers{end+1} = struct('type', 'relu', 'name', sprintf('relu%d',32)) ;
        
        %% wider layers for better performance 
        net = addBlock(net, opts, 4, 1, 1, J, 1500, 1, 0);
        net = addBlock(net, opts, 4, 1, 1, 1500, 1, 1, 0);

        %% cvpr paper
        %net = addBlock(net, opts, 4, 1, 1, J, 900, 1, 0);
        %net = addBlock(net, opts, 4, 1, 1, 900, 1, 1, 0);

        net.layers(end-1:end) = [];
    
        net.layers{end+1} = struct( ...
            'name', 'mcqLoss',...
        'type', 'custom', ...
        'forward', @(layer, res_i, res_ip1) mcqMaxMarginLossLayer( ...
            layer, res_i, res_ip1, true), ...
        'backward', @(layer, res_i, res_ip1) mcqMaxMarginLossLayer( ...
            layer, res_i, res_ip1, false), ...
        'gt_labels', []);
        
end